{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e13f17c-b60a-4888-8c5d-e602d27b7171",
   "metadata": {},
   "source": [
    "## Predicting Primary Hashtag Category on Instagram Posts Using KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4b031d-b021-4049-8985-3d4262cc38a0",
   "metadata": {},
   "source": [
    "#### üöÄ Let‚Äôs walk through a full ML workflow with our selected dataset using KNN(K-Nearest Neighbors)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bf5ee0-3ea5-4afa-9182-935f42e858dc",
   "metadata": {},
   "source": [
    "### 1. Problem Definition\n",
    "\n",
    "##### Goal: Predict the primary hashtag category of an Instagram post based on engagement metrics and traffic sources.\n",
    "\n",
    "##### Input: Numeric engagement and traffic features per post\n",
    "\n",
    "##### Output: Predicted hashtag category (top 5 hashtags + ‚ÄúOther‚Äù)\n",
    "\n",
    "##### Why: Understanding what type of content users engage with helps optimize posting strategy and predict content popularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4e465a-1e87-4f73-ad02-ead044e207df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                                      # For data manipulation and analysis\n",
    "from sklearn.model_selection import train_test_split     # To split data into train/test sets\n",
    "from sklearn.preprocessing import StandardScaler         # To scale numeric features\n",
    "from sklearn.neighbors import KNeighborsClassifier       # KNN classifier\n",
    "from sklearn.metrics import accuracy_score, f1_score     # For model evaluation\n",
    "import matplotlib.pyplot as plt                          # For plotting results\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ebefa2-4136-4503-ac65-514dfd80a0fc",
   "metadata": {},
   "source": [
    "### 2. Input Data (Features)\n",
    "##### We download 'Instagram data.csv' from link https://www.kaggle.com/datasets/amirmotefaker/instagram-data?utm_source=chatgpt.com \n",
    "##### Impressions : \n",
    "###### Total number of times the post was displayed on users‚Äô screens. Use for: Higher impressions may indicate more exposure, affecting engagement and content popularit\n",
    "##### From Home :\n",
    "###### Number of impressions coming from users‚Äô home feeds. Use for : Shows organic reach from followers or the home timeline. May correlate with engagement among existing followers.\n",
    "##### From Hashtags :\n",
    "###### Number of impressions coming from users clicking hashtags associated with the post. Use for: Indicates discoverability via hashtags; can affect which hashtags users engage with.\n",
    "##### From Explore :\n",
    "###### Impressions coming from the Explore page (Instagram‚Äôs content discovery area). Use for: Signals reach beyond followers; can help predict content virality.\n",
    "##### From Other :\n",
    "###### Impressions from sources not listed above (e.g., direct shares, external links). Use for: Less transparent source; may indicate broader spread or referral traffic.\n",
    "##### Saves :\n",
    "###### Number of times users saved the post. Use for: Strong indicator of content value/interest; more meaningful engagement than just likes.\n",
    "##### Comments :\n",
    "###### Number of comments on the post. Use for: Direct measure of interaction; helps gauge engagement depth.\n",
    "##### Shares :\n",
    "###### Number of times the post was shared by users. Use for: Indicates content virality potential; can signal which hashtags attract sharing.\n",
    "##### Likes :\n",
    "###### Number of likes on the post. Use for: Basic engagement metric; combined with other metrics gives total interaction.\n",
    "##### Profile Visits : \n",
    "###### Number of users who visited the account‚Äôs profile from the post. Use for: Can indicate interest in the account or content type, useful for predicting user behavior.\n",
    "##### Follows :\n",
    "###### Number of new followers gained from this post. Use for: Strong engagement/interest indicator; posts generating new followers may correlate with popular hashtags.\n",
    "##### Caption :\n",
    "###### Text content of the post caption. Use for: Contains hashtags, keywords, or content context. Can be used for NLP feature extraction if needed.\n",
    "##### Hashtags :\n",
    "###### List of hashtags used in the post. Use for: Target variable in our model; primary hashtags indicate topic/interest category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e362df-ec8c-4045-9afc-85d3b620a713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Data (Features)\n",
    "df = pd.read_csv(r\".\\data\\Instagram data.csv\", encoding='ISO-8859-1')     # Read CSV into DataFrame\n",
    "print(\"Columns from dataset:\")\n",
    "df.columns                                                                # List all column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b9423a-8e4d-4717-8bbf-626b62b34e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Selected numeric features for modeling :\")\n",
    "numeric_features = [\n",
    "    'Impressions', 'From Home', 'From Hashtags', 'From Explore', 'From Other',\n",
    "    'Saves', 'Comments', 'Shares', 'Likes', 'Profile Visits', 'Follows'\n",
    "]\n",
    "numeric_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2abea1-6d87-42aa-89c3-dc847f158747",
   "metadata": {},
   "source": [
    "### 3. Preprocessing Steps\n",
    "\n",
    "##### 3.1. Handle missing values\n",
    "###### - Avoid SettingWithCopyWarning using .copy()\n",
    "###### - Fill missing numeric values with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d51a11-4c5f-4f3d-ba70-ee3d2d0ce404",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[numeric_features].copy()       # Copy selected features to X to avoid warnings\n",
    "X.fillna(0, inplace=True)             # Replace any remaining NaN values with 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d185de1c-f243-4087-99c9-e62307aa34b2",
   "metadata": {},
   "source": [
    "##### 3.2. Feature engineering\n",
    "###### - Reasoning: Ratios normalize features across posts with different reach, making KNN distances meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e544222-78a6-4e4c-9ada-d5006a13eb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute engagement rate as total interactions / impressions\n",
    "X['EngagementRate'] = (X['Likes'] + X['Comments'] + X['Shares'] + X['Saves']) / X['Impressions'].replace(0, 1)\n",
    "\n",
    "# Compute traffic source ratios to normalize impressions per source\n",
    "X['FromHashtagsRate'] = X['From Hashtags'] / X['Impressions'].replace(0, 1)\n",
    "X['FromExploreRate'] = X['From Explore'] / X['Impressions'].replace(0, 1)\n",
    "X['FromHomeRate'] = X['From Home'] / X['Impressions'].replace(0, 1)\n",
    "X['FromOtherRate'] = X['From Other'] / X['Impressions'].replace(0, 1)\n",
    "\n",
    "\n",
    "# Extract primary hashtag (first one in the list)\n",
    "df['PrimaryHashtag'] = df['Hashtags'].apply(lambda x: str(x).split()[0] if pd.notnull(x) else 'None')\n",
    "\n",
    "# Reduce to top 5 hashtags + 'Other' to simplify classification\n",
    "top_hashtags = df['PrimaryHashtag'].value_counts().nlargest(5).index\n",
    "df['HashtagCategory'] = df['PrimaryHashtag'].apply(lambda x: x if x in top_hashtags else 'Other')\n",
    "\n",
    "y = df['HashtagCategory']    # Assign target variable for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654094b6-f600-4f81-965b-9581ff7d5a10",
   "metadata": {},
   "source": [
    "##### 3.3. Scale features\n",
    "###### - Standardization ensures all features contribute equally to distance calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb1b04a-5ecf-4863-9633-8280483c54ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()            # Create scaler object\n",
    "X_scaled = scaler.fit_transform(X)   # Fit scaler and transform X to normalized values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d7fd4c-5d5b-4ee3-b1ed-6895099c9483",
   "metadata": {},
   "source": [
    "### 4. Train/Test Split\n",
    "###### - 80% training, 20% testing\n",
    "###### - Random state ensures reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a380c5ea-e848-4aa8-b7a8-3f567a64642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42     # 80% train, 20% test, reproducible split\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd19fa93-33c7-4ae9-bf1b-6b8ae9455fd4",
   "metadata": {},
   "source": [
    "### 5. Model\n",
    "\n",
    "##### Use K-Nearest Neighbors (KNN):\n",
    "\n",
    "##### Why KNN?\n",
    "\n",
    "###### a- Numeric features dominate the dataset\n",
    "\n",
    "###### - Columns like Likes, Comments, Shares, Saves, Impressions, Profile Visits, Follows, and traffic sources (From Home, From Hashtags, From Explore, From Other) are all numeric.\n",
    "\n",
    "###### - KNN works naturally on numeric data by computing distances, so it can measure similarity between posts based on engagement patterns.\n",
    "\n",
    "###### b- No assumptions about data distribution\n",
    "\n",
    "###### - Engagement metrics are often skewed or non-linear (e.g., a viral post may have extremely high likes).\n",
    "\n",
    "###### - KNN is non-parametric and does not assume a normal or linear distribution, so it adapts to these patterns.\n",
    "\n",
    "###### c- Small-to-medium dataset\n",
    "\n",
    "###### - KNN performs well when the dataset is not huge.\n",
    "\n",
    "###### - With a manageable number of Instagram posts, computing distances is fast and accurate.\n",
    "\n",
    "###### d- Predicting categories based on ‚Äúsimilar posts‚Äù\n",
    "\n",
    "###### - The target is Primary Hashtag Category.\n",
    "\n",
    "###### - It makes sense that a post will likely belong to the same hashtag category as other posts with similar engagement and traffic patterns.\n",
    "\n",
    "###### - KNN directly leverages this principle by finding the nearest neighbors in feature space.\n",
    "\n",
    "###### e- Interpretability\n",
    "\n",
    "###### - We can examine which posts (neighbors) influenced the classification.\n",
    "\n",
    "###### - This is helpful for content strategy: for example, posts with high From Hashtags and EngagementRate that fall into a particular hashtag category.\n",
    "\n",
    "##### Why KNN might struggle here\n",
    "###### - If the number of hashtags/classes is very large, KNN performance drops ‚Äî which is why we reduced it to top 5 hashtags + ‚ÄúOther‚Äù.\n",
    "###### - Features must be scaled (we used StandardScaler and engineered ratios) to avoid dominance by large-count features like Impressions.\n",
    "\n",
    "##### Reasoning:\n",
    "###### - KNN is intuitive and distance-based, suitable for numeric data\n",
    "###### - Tested multiple k values to find optimal neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd3965e-9342-4f5e-8905-0e8c141153ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = range(1, 21)                                         # Try k from 1 to 20\n",
    "accuracies = []                                                 # Store accuracy for each k\n",
    "f1_scores = []                                                  # Store weighted F1-score for each k\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)                   # Initialize KNN with k neighbors\n",
    "    knn.fit(X_train, y_train)                                   # Train KNN on training data\n",
    "    y_pred = knn.predict(X_test)                                # Predict classes for test set\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)                        # Compute accuracy\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')           # Compute weighted F1-score\n",
    "    \n",
    "    accuracies.append(acc)                                      # Save accuracy\n",
    "    f1_scores.append(f1)                                        # Save F1-score\n",
    "    print(f'k={k}: Accuracy={acc:.3f}, F1-score={f1:.3f}')      # Print results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7f9ed8-65b4-4608-b602-5c5542c2dd38",
   "metadata": {},
   "source": [
    "### 6. Evaluation\n",
    "\n",
    "##### Observations from previous run:\n",
    "\n",
    "###### &nbsp;&nbsp;k&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Accuracy&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;F1-score\n",
    "###### &nbsp;&nbsp;8&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.708&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.722\n",
    "###### &nbsp;&nbsp;9&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.667&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.670\n",
    "###### &nbsp;&nbsp;12&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.625&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.617\n",
    "\n",
    "#### Best k: 8\n",
    "\n",
    "###### Engagement ratios and traffic source ratios improved prediction significantly\n",
    "\n",
    "#### KNN struggles with very small or very large k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad96ed-9043-4e61-a206-bfe00301d3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))                                    # Set figure size\n",
    "plt.plot(k_values, accuracies, marker='o', label='Accuracy')   # Plot accuracy\n",
    "plt.plot(k_values, f1_scores, marker='s', label='F1-score')    # Plot F1-score\n",
    "plt.xlabel('Number of Neighbors (k)')                          # Label x-axis\n",
    "plt.ylabel('Score')                                            # Label y-axis\n",
    "plt.title('KNN Performance with Engineered Features')          # Plot title\n",
    "plt.legend()                                                   # Show legend\n",
    "plt.grid(True)                                                 # Show grid\n",
    "plt.show()                                                     # Display plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525db334-06e4-4d0d-9e6d-ea516132af74",
   "metadata": {},
   "source": [
    "### 7. Insights and Recommendations\n",
    "\n",
    "###### 7.1. Feature engineering matters: Normalized ratios improve KNN performance.\n",
    "\n",
    "###### 7.2. Reducing classes helps: Predicting top 5 hashtags + Other avoids sparse classes.\n",
    "\n",
    "###### 7.3. KNN is simple and interpretable, but may be outperformed by tree-based methods (Random Forest, Gradient Boosting) for multi-class problems.\n",
    "\n",
    "###### 7.4. Optimal k depends on dataset size and class distribution ‚Äî in our case, k=8 worked best."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
