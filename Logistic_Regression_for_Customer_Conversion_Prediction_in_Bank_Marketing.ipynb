{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b80f2ed3-4dea-4efe-a428-7695eae2a961",
   "metadata": {},
   "source": [
    "## Logistic Regression for Customer Conversion Prediction in Bank Marketing\n",
    "### Dataset choice\n",
    "##### Bank Marketing (UCI / Kaggle) — binary classification problem (y: subscription yes/no).\n",
    "\n",
    "###### - Real, tabular, mixed categorical + numeric features (age, job, balance, campaign, poutcome, contact, etc.).\n",
    "\n",
    "###### - Good size for experiments and realistic results.\n",
    "\n",
    "##### - Logistic Regression is appropriate because: \n",
    "###### &nbsp;&nbsp;&nbsp;&nbsp;-interpretable coefficients\n",
    "###### &nbsp;&nbsp;&nbsp;&nbsp;-works well for binary outcomes\n",
    "###### &nbsp;&nbsp;&nbsp;&nbsp;-allows regularization\n",
    "###### &nbsp;&nbsp;&nbsp;&nbsp;-is a solid baseline you can improve\n",
    "\n",
    "### 1. Problem\n",
    "\n",
    "##### Predict whether a client will subscribe to a term deposit (y = 'yes' / 'no').\n",
    "\n",
    "###### Binary classification → Logistic Regression is a natural baseline.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b649f7d3-2f24-4658-9775-e995cb5d7ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Imports ----------\n",
    "import pandas as pd                                   # data manipulation\n",
    "import numpy as np                                    # numerical operations\n",
    "import matplotlib.pyplot as plt                       # plotting\n",
    "import seaborn as sns                                 # plotting helper\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV  # splitting & hyperparam search\n",
    "from sklearn.preprocessing import StandardScaler      # feature scaling\n",
    "from sklearn.linear_model import LogisticRegression   # logistic regression model\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, classification_report, confusion_matrix,\n",
    "                             roc_curve, roc_auc_score)  # evaluation metrics\n",
    "import warnings                                       # ignore warnings for clean output\n",
    "warnings.filterwarnings(\"ignore\")                     # suppress warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6d9312-43d6-4746-a787-fe0413794bc6",
   "metadata": {},
   "source": [
    "### 2. Input Data (features)\n",
    "\n",
    "##### Typical columns (UCI bank-full):\n",
    "\n",
    "###### - age (numeric)\n",
    "\n",
    "###### - job, marital, education (categorical)\n",
    "\n",
    "###### - default (has credit in default: yes/no)\n",
    "\n",
    "###### - balance (numeric)\n",
    "\n",
    "###### - housing (yes/no), loan (yes/no)\n",
    "\n",
    "###### - contact (categorical: telephone / cellular)\n",
    "\n",
    "###### - day, month (time of contact)\n",
    "\n",
    "###### - duration (call duration in secs) — note: in many studies duration is dropped for true predictive modelling because it is only known after the call; I'll exclude it by default for realistic predictions (I’ll explain in the code).\n",
    "\n",
    "###### - campaign, pdays, previous (campaign-related numeric features)\n",
    "\n",
    "###### - poutcome (outcome of previous campaign)\n",
    "\n",
    "###### - y — target: subscribe yes/no\n",
    "\n",
    "##### - Read CSV with correct delimiter.\n",
    "\n",
    "##### - Inspect columns and target distribution.\n",
    "\n",
    "##### - Drop duration for realistic prediction (it leaks post-call information). (Optional: keep it if you want best possible offline performance.)\n",
    "\n",
    "##### - Encode target y → binary (1 for yes, 0 for no).\n",
    "\n",
    "##### - Handle missing values (this dataset typically has no NAs, but code checks).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f92ce45-cd07-4831-8c5f-e455a2f4871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 1. Load dataset ----------\n",
    "# (UCI Bank Marketing CSV uses semicolon ; as delimiter)\n",
    "df = pd.read_csv(r\".\\data\\bank-full.csv\", sep=';')                 # load CSV into DataFrame\n",
    "\n",
    "# ---------- 2. Quick inspection ----------\n",
    "print(\"\\n--- Dataset Shape ---\")\n",
    "print(\"Shape:\", df.shape)                             # print number of rows and columns\n",
    "print(\"\\n--- Columns ---\")\n",
    "print(df.columns.tolist())                            # list column names\n",
    "print(\"\\n--- Sample Rows ---\")\n",
    "print(df['y'].value_counts(dropna=False))             # see target distribution (yes/no)\n",
    "\n",
    "# ---------- 3. Clean / Basic preprocessing ----------\n",
    "# For realistic predictive modelling, drop 'duration' because it is only known after the call\n",
    "# (including it will inflate offline performance but is not available when deciding to call).\n",
    "if 'duration' in df.columns:\n",
    "    df = df.drop(columns=['duration'])                # remove duration to avoid target leakage\n",
    "\n",
    "# Convert target 'y' from yes/no to binary 1/0\n",
    "df['y'] = df['y'].map({'yes': 1, 'no': 0})           # map yes->1, no->0\n",
    "\n",
    "# Quick NA check (this dataset normally has no missing values)\n",
    "print(\"Missing values per column:\\n\", df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faace7a3-2729-40ba-b286-3de64417ce25",
   "metadata": {},
   "source": [
    "### 3. Preprocessing (what we’ll do and why)\n",
    "\n",
    "###### - Convert categorical variables → numeric via pd.get_dummies (one-hot); for high-cardinality features we may group rare categories.\n",
    "\n",
    "###### - Feature engineering: e.g., previous > 0 → has_previous, derive age_group optionally. (I include a simple has_previous example.)\n",
    "\n",
    "###### - Scale numeric features with StandardScaler (important for regularized Logistic Regression).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c72a1b-e80a-499f-ace0-c1edccb64f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- 4. Feature engineering ----------\n",
    "# create a simple engineered feature: whether customer had previous contacts\n",
    "if 'previous' in df.columns:\n",
    "    df['has_previous'] = (df['previous'] > 0).astype(int)  # 1 if previous contacts > 0 else 0\n",
    "\n",
    "# Optionally group rare job categories (example)\n",
    "if 'job' in df.columns:\n",
    "    job_counts = df['job'].value_counts()\n",
    "    rare_jobs = job_counts[job_counts < 100].index.tolist()  # threshold=100, adjust as needed\n",
    "    df['job_group'] = df['job'].replace(rare_jobs, 'other')   # replace rare jobs with 'other'\n",
    "\n",
    "# ---------- 5. Select features and target ----------\n",
    "# Choose a list of candidate features (numeric + categorical)\n",
    "candidate_features = [\n",
    "    'age', 'balance', 'campaign', 'pdays', 'previous',\n",
    "    'has_previous', 'job_group', 'marital', 'education',\n",
    "    'default', 'housing', 'loan', 'contact', 'month', 'day', 'poutcome'\n",
    "]\n",
    "# Keep only features that exist in the dataset (some versions differ)\n",
    "features = [f for f in candidate_features if f in df.columns]\n",
    "X = df[features].copy()                               # feature DataFrame copy\n",
    "y = df['y'].copy()                                    # target series\n",
    "\n",
    "# ---------- 6. Categorical encoding ----------\n",
    "# Identify categorical columns in X (object or category dtype)\n",
    "cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "print(\"Categorical columns to encode:\", cat_cols)\n",
    "\n",
    "# One-hot encode categorical variables; drop_first=True reduces multicollinearity\n",
    "X_encoded = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n",
    "\n",
    "# ---------- 7. Numeric scaling ----------\n",
    "# Identify numeric columns after encoding (all columns will be numeric dtype)\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(\"Numeric columns to scale:\", numeric_cols)\n",
    "\n",
    "# We'll scale numeric columns (important for regularized logistic regression)\n",
    "scaler = StandardScaler()                             # create scaler\n",
    "# Fit scaler on numeric columns and transform\n",
    "X_encoded[numeric_cols] = scaler.fit_transform(X_encoded[numeric_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9cfe5e-f0e0-4eb7-9bf5-197fdd1d1efd",
   "metadata": {},
   "source": [
    "### 4. Train/Test split\n",
    "###### - Split the dataset into training (80%) and test (20%) sets using train_test_split; stratify by target to maintain class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cbafea-ff29-44a2-b8b7-b205340fccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 8. Train/Test split (80/20) ----------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f456c4f-016a-4a72-9e2b-0bd1985d9eb6",
   "metadata": {},
   "source": [
    "### 5. Model (Baseline)\n",
    "###### - Fit the baseline Logistic Regression model on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f698a8ac-9c1c-4719-94af-24e053910a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 9. Baseline Logistic Regression (no tuning) ----------\n",
    "baseline_clf = LogisticRegression(solver='liblinear', random_state=42)  # initialize model\n",
    "baseline_clf.fit(X_train, y_train)                    # train model on training set\n",
    "\n",
    "# Baseline predictions\n",
    "y_pred_base = baseline_clf.predict(X_test)            # predicted labels\n",
    "y_proba_base = baseline_clf.predict_proba(X_test)[:, 1]  # predicted probabilities for positive class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1760f3b-51fd-4023-8d57-9865ee63a2fe",
   "metadata": {},
   "source": [
    "### 6. Evaluation (Baseline)\n",
    "###### - valuate the baseline model using metrics: accuracy, precision, recall, F1-score, confusion matrix, ROC-AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc4cfe6-9bb0-4c9a-8c1f-6036ce6a9e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 10. Baseline evaluation ----------\n",
    "print(\"Baseline Accuracy:\", accuracy_score(y_test, y_pred_base))          # overall accuracy\n",
    "print(\"Baseline Precision:\", precision_score(y_test, y_pred_base))       # precision\n",
    "print(\"Baseline Recall:\", recall_score(y_test, y_pred_base))             # recall\n",
    "print(\"Baseline F1:\", f1_score(y_test, y_pred_base))                     # F1-score\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_base))  # detailed report\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_base)            # compute confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", cm)                      # print confusion matrix\n",
    "\n",
    "# ROC AUC\n",
    "roc_auc_base = roc_auc_score(y_test, y_proba_base)    # compute AUC\n",
    "print(\"Baseline ROC AUC:\", roc_auc_base)              # print AUC\n",
    "\n",
    "# Plot ROC curve for baseline\n",
    "fpr_base, tpr_base, _ = roc_curve(y_test, y_proba_base)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr_base, tpr_base, label=f'Baseline (AUC = {roc_auc_base:.3f})')\n",
    "plt.plot([0,1], [0,1], '--', color='gray')            # random guess line\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - Baseline Logistic Regression\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee678159-51d3-4559-9b76-7d3bca960195",
   "metadata": {},
   "source": [
    "### 7. Model (Tuned)\n",
    "###### - Hyperparameter tuning with GridSearchCV or other techniques (e.g., class weights, regularization) to optimize model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785c2f4c-33a5-4b41-aa6a-334029ea6e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 11. Hyperparameter tuning (GridSearchCV) ----------\n",
    "# We tune penalty (l1/l2) and C (inverse of regularization strength). Also try class_weight balance.\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],                          # L1 -> feature selection; L2 -> ridge-like\n",
    "    'C': [0.01, 0.1, 1, 10],                          # regularization strengths\n",
    "    'class_weight': [None, 'balanced']                # handle class imbalance\n",
    "}\n",
    "# Use liblinear solver because it supports l1 penalty\n",
    "grid = GridSearchCV(LogisticRegression(solver='liblinear', random_state=42),\n",
    "                    param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid.fit(X_train, y_train)                            # run grid search on training data\n",
    "\n",
    "# Best params and CV score\n",
    "print(\"Best params:\", grid.best_params_)              # print best hyperparameters\n",
    "print(\"Best CV F1:\", grid.best_score_)                # best cross-validated F1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cf40a3-3826-46b1-9bb0-1c26ee932746",
   "metadata": {},
   "source": [
    "### 8.Evaluation (Tuned)\n",
    "###### - Evaluate the tuned model on the test set with the same metrics as baseline: accuracy, precision, recall, F1, confusion matrix, ROC-AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25364bd-ca2c-404a-b3b9-88a49d527322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 12. Evaluate tuned model on test set ----------\n",
    "best_clf = grid.best_estimator_                       # retrieve best estimator\n",
    "y_pred_tuned = best_clf.predict(X_test)               # predictions from tuned model\n",
    "y_proba_tuned = best_clf.predict_proba(X_test)[:, 1]  # probabilities from tuned model\n",
    "\n",
    "# Metrics for tuned model\n",
    "print(\"Tuned Accuracy:\", accuracy_score(y_test, y_pred_tuned))\n",
    "print(\"Tuned Precision:\", precision_score(y_test, y_pred_tuned))\n",
    "print(\"Tuned Recall:\", recall_score(y_test, y_pred_tuned))\n",
    "print(\"Tuned F1:\", f1_score(y_test, y_pred_tuned))\n",
    "print(\"\\nTuned Classification Report:\\n\", classification_report(y_test, y_pred_tuned))\n",
    "\n",
    "# Confusion matrix for tuned model\n",
    "cm_tuned = confusion_matrix(y_test, y_pred_tuned)\n",
    "print(\"Tuned Confusion Matrix:\\n\", cm_tuned)\n",
    "\n",
    "# ROC AUC for tuned model\n",
    "roc_auc_tuned = roc_auc_score(y_test, y_proba_tuned)\n",
    "print(\"Tuned ROC AUC:\", roc_auc_tuned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a2bcff-c5ed-48a6-b0ec-2e7d9cb83cb6",
   "metadata": {},
   "source": [
    "### Analyze Current Model\n",
    "\n",
    "###### - Baseline accuracy is high (~ 0.89) but precision/recall for positive class is low → class imbalance problem.\n",
    "\n",
    "###### - Tuned model improved recall (~ 0.63) but precision dropped (~ 0.27) → more true positives but many false positives.\n",
    "\n",
    "##### Goal: improve F1-score and balance precision/recall.\n",
    "\n",
    "### Possible Improvements\n",
    "\n",
    "##### Handle Class Imbalance\n",
    "\n",
    "##### &nbsp;&nbsp;&nbsp;&nbsp; - Use class_weight='balanced' in Logistic Regression.\n",
    "\n",
    "###### &nbsp;&nbsp;&nbsp;&nbsp; - Try SMOTE or undersampling the majority class.\n",
    "\n",
    "##### Feature Selection / Engineering\n",
    "\n",
    "###### &nbsp;&nbsp;&nbsp;&nbsp; - Check which features are most important (correlations, coefficients).\n",
    "\n",
    "###### &nbsp;&nbsp;&nbsp;&nbsp; - Combine or transform features (e.g., interaction terms).\n",
    "\n",
    "##### Regularization\n",
    "\n",
    "###### &nbsp;&nbsp;&nbsp;&nbsp; - Tune C parameter for L1/L2 regularization.\n",
    "\n",
    "###### &nbsp;&nbsp;&nbsp;&nbsp; - L1 can also do feature selection.\n",
    "\n",
    "##### Scaling\n",
    "\n",
    "###### &nbsp;&nbsp;&nbsp;&nbsp; - Standardize numeric features for better convergence (e.g., StandardScaler).\n",
    "\n",
    "##### Cross-validation\n",
    "\n",
    "###### &nbsp;&nbsp;&nbsp;&nbsp; - Use StratifiedKFold CV to evaluate more robustly than a single train/test split.\n",
    "\n",
    "### 9. Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eef127b-058d-4351-b36f-3c6e2c3aba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "# ---------- 1. Load dataset ----------\n",
    "# (UCI Bank Marketing CSV uses semicolon ; as delimiter)\n",
    "df = pd.read_csv(r\".\\data\\bank-full.csv\", sep=';')                 # load CSV into DataFrame\n",
    "\n",
    "# ---------- 2. Quick inspection ----------\n",
    "print(\"\\n--- Dataset Shape ---\")\n",
    "print(\"Shape:\", df.shape)                             # print number of rows and columns\n",
    "print(\"\\n--- Columns ---\")\n",
    "print(df.columns.tolist())                            # list column names\n",
    "print(\"\\n--- Sample Rows ---\")\n",
    "print(df['y'].value_counts(dropna=False))             # see target distribution (yes/no)\n",
    "\n",
    "# ---------- 3. Check Missing Values ----------\n",
    "print(\"\\n--- Missing Values ---\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# The dataset usually has no true NaN values, but we check to be safe.\n",
    "\n",
    "# ---------- 5. Encode Categorical Variables ----------\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "numeric_cols = df.select_dtypes(exclude=[\"object\"]).columns\n",
    "\n",
    "print(\"\\n--- Categorical Columns ---\")\n",
    "print(categorical_cols)\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "X_encoded = pd.get_dummies(df.drop(\"y\", axis=1), drop_first=True)\n",
    "\n",
    "# ---------- 6. Feature Engineering ----------\n",
    "# Here we can add new features if needed (none added yet)\n",
    "# Example: interaction terms, binning, ratios, etc.\n",
    "\n",
    "# ---------- 7. Drop Unnecessary Columns ----------\n",
    "# Nothing to drop here beyond 'y', already handled above.\n",
    "\n",
    "# ---------- 8. Select Features and Target ----------\n",
    "X = X_encoded.copy()\n",
    "y = df[\"y\"].map({\"no\": 0, \"yes\": 1})  # convert target to 0/1\n",
    "\n",
    "# ---------- 9. Sanity Check ----------\n",
    "print(\"\\n--- Sanity Check ---\")\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"Any NaN in X?\", X.isnull().sum().sum())\n",
    "print(\"Any NaN in y?\", y.isnull().sum())\n",
    "\n",
    "# Fill any unexpected NaNs with 0\n",
    "X = X.fillna(0)\n",
    "\n",
    "# ---------- 10. Train/Test Split ----------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ---------- 11. Baseline Model (Default Logistic Regression) ----------\n",
    "baseline_model = LogisticRegression(max_iter=1000, solver=\"liblinear\")\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_base = baseline_model.predict(X_test)\n",
    "y_prob_base = baseline_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n--- Baseline Evaluation ---\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_base))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_base))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_base))\n",
    "print(\"F1:\", f1_score(y_test, y_pred_base))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_base))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_base))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob_base))\n",
    "\n",
    "# ---------- 12. Hyperparameter Tuning ----------\n",
    "param_grid = {\n",
    "    \"C\": [0.01, 0.1, 1, 10],\n",
    "    \"penalty\": [\"l1\", \"l2\"],\n",
    "    \"solver\": [\"liblinear\"]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5, scoring=\"f1\")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n--- Best Hyperparameters ---\")\n",
    "print(grid.best_params_)\n",
    "\n",
    "# ---------- 13. Tuned Model Evaluation ----------\n",
    "tuned_model = grid.best_estimator_\n",
    "y_pred_tuned = tuned_model.predict(X_test)\n",
    "y_prob_tuned = tuned_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n--- Tuned Evaluation ---\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_tuned))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_tuned))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_tuned))\n",
    "print(\"F1:\", f1_score(y_test, y_pred_tuned))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_tuned))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_tuned))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob_tuned))\n",
    "\n",
    "# ---------- 14. Visualization ----------\n",
    "# Confusion Matrix Heatmap\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_tuned), annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix (Tuned Model)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "RocCurveDisplay.from_estimator(tuned_model, X_test, y_test)\n",
    "plt.title(\"ROC Curve (Tuned Model)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e5f1b3-68d8-4233-842f-2d550f354c11",
   "metadata": {},
   "source": [
    "### 10. Visualization\n",
    "###### - Plot results or analyze feature importance (coefficients), confusion matrix heatmaps, ROC curves, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376a28c6-1404-482c-81ee-820f4c996d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 13. Compare ROC curves (baseline vs tuned) ----------\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr_base, tpr_base, label=f'Baseline (AUC={roc_auc_base:.3f})', color='blue')  # baseline ROC\n",
    "fpr_tuned, tpr_tuned, _ = roc_curve(y_test, y_proba_tuned)    # tuned ROC\n",
    "plt.plot(fpr_tuned, tpr_tuned, label=f'Tuned (AUC={roc_auc_tuned:.3f})', color='green') # tuned ROC\n",
    "plt.plot([0,1], [0,1], '--', color='gray')                  # random guess\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve Comparison: Baseline vs Tuned\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb3b64c-42cd-465e-a2fb-8d05d4cae3bd",
   "metadata": {},
   "source": [
    "### 11.Save Model\n",
    "###### - Save the trained/tuned model for later use (e.g., joblib.dump)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4535661-fd95-42bc-adf3-6b42e7fb4c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 14. Inspect logistic regression coefficients (feature importances) ----------\n",
    "# Coefficients map to X_encoded column order\n",
    "coefficients = pd.Series(best_clf.coef_[0], index=X_encoded.columns)  # map coef vector to feature names\n",
    "coefficients = coefficients.sort_values(key=lambda x: np.abs(x), ascending=False)  # sort by absolute value\n",
    "print(\"Top coefficients:\\n\", coefficients.head(20))    # print top 20 influential features\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
